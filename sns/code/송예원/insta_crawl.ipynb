{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium\n",
    "pip install webdriver_manager\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def account_crawler(account, num_posts):\n",
    "    post_num = 1\n",
    "    next_butt = 0\n",
    "    i = 0\n",
    "    for posts in range(1, num_posts+1):\n",
    "\n",
    "        # Text & Tags\n",
    "        raw_text = driver.find_element(By.CSS_SELECTOR, 'div._a9zr')\n",
    "        text = raw_text.text\n",
    "\n",
    "        # Likes\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        likes = soup.find_all('span', attrs={'html-span xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x1hl2dhg x16tdsg8 x1vvkbs'})[-1].text\n",
    "\n",
    "        #Time \n",
    "        post_date = driver.find_element(By.CSS_SELECTOR, 'time.x1p4m5qa').text\n",
    "\n",
    "        #Add row to dataframe\n",
    "        add_elements = [account, post_num, post_date, text, likes]\n",
    "        insta_post_df.loc[i]=add_elements\n",
    "        print(f'{i+1} post crawled') ; print(add_elements) ; print(' ')\n",
    "\n",
    "        # Move next\n",
    "        driver.find_elements(By.CSS_SELECTOR, 'button._abl-')[next_butt].click()\n",
    "        next_butt=1 ; post_num+=1 ; i+=1\n",
    "        time.sleep(3)\n",
    "\n",
    "    return insta_post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_post_df = pd.DataFrame(columns=['account','post_num', 'post_date', 'text','num_likes'])\n",
    "lotte_crawler = account_crawler('lottecinema_official', 1222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_post_df.to_csv('lotte1.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
